{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d427058",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c687e11",
   "metadata": {},
   "source": [
    "# Add company info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75bb37bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "company_original = pd.read_csv(\"companies.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed056d9a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "company_original.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2188d0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "company_original.loc[company_original['permalink'] == '/organization/goot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d337c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read \n",
    "company_domain = pd.read_csv(\"Companies_domain.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d879257",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get Domain file to join on PERMALINK to get DOMAIN COLUMN FROM company_domain dataframe\n",
    "\n",
    "company = pd.merge(company_original,company_domain[['permalink','Domain']],on='permalink', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc8babc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "company.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211d1e6f",
   "metadata": {},
   "source": [
    "# Add investment data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2003ff85",
   "metadata": {},
   "outputs": [],
   "source": [
    "investment_feature = pd.read_csv(\"investments.csv\")\n",
    "investment_feature.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63194c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "investment_feature.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1deb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "investment_feature.drop_duplicates(subset = ['company_permalink'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34fa81b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "company_investment = pd.merge(company,investment_feature, left_on = 'permalink', right_on = 'company_permalink', how = 'left') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec2b60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "company_investment.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "981d0f69",
   "metadata": {},
   "source": [
    "# New feature creation - Num of investor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190734c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_invest = company_investment[['company_permalink',\n",
    "                         'investor_permalink']].groupby(['company_permalink']).size().reset_index(name = 'Num_of_investors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907fb4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "company_investment1 = pd.merge(company_investment,num_of_invest, left_on = 'permalink', right_on = 'company_permalink', how = 'left')# 66368 total row count\n",
    "\n",
    "\n",
    "company_investment1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1aa1058",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_company = company_investment1.drop_duplicates(subset = ['permalink'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b9a01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_company.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac58063f",
   "metadata": {},
   "source": [
    "# Add rounds datset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7331c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "rounds_feature = pd.read_csv(\"rounds.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c959c197",
   "metadata": {},
   "outputs": [],
   "source": [
    "rounds_feature.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0e9ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rounddf = rounds_feature.drop_duplicates(subset = ['company_permalink']) #66368"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a65b38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rounddf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7368d720",
   "metadata": {},
   "outputs": [],
   "source": [
    "company_inv_round = pd.merge(final_company,rounddf, left_on = 'permalink', right_on = 'company_permalink', how = 'left')# 66368 total row count\n",
    "\n",
    "\n",
    "company_inv_round.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5013b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd. set_option('display.max_columns', 500)\n",
    "company_inv_round.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dafb5e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = company_inv_round.drop(columns = ['company_permalink_x','company_name_x','company_country_code_x','company_state_code_x',\n",
    "                                   'company_region_x','company_city_x','funding_round_permalink_x',\n",
    "                                   'funding_round_type_x','funded_at_x','raised_amount_usd_x','company_permalink_y','company_name_y',\n",
    "                                  'company_category_list_y','company_country_code_y','company_state_code_y','company_region_y',\n",
    "                                   'company_city_y','funding_round_permalink_y','funding_round_code_y','company_permalink',\n",
    "                                             'investor_state_code','investor_region','investor_city','company_category_list_x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9013df",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebcb59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef3d0e1",
   "metadata": {},
   "source": [
    "# Convert funding_total_usd from string to numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fea1e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['funding_total_usd'] = pd.to_numeric(final_df['funding_total_usd'], errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321c1533",
   "metadata": {},
   "source": [
    "# fill null or Na values to mode values for all features having NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a5d1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['category_list'].fillna(final_df['category_list'].mode()[0], inplace=True)\n",
    "final_df['country_code'].fillna(final_df['country_code'].mode()[0], inplace=True)\n",
    "final_df['funding_rounds'].fillna(final_df['funding_rounds'].mode()[0], inplace=True)\n",
    "final_df['founded_at'].fillna(final_df['founded_at'].mode()[0], inplace=True)\n",
    "final_df['funding_round_type_y'].fillna(final_df['funding_round_type_y'].mode()[0], inplace=True)\n",
    "final_df['funding_round_code_x'].fillna(final_df['funding_round_code_x'].mode()[0], inplace=True)\n",
    "final_df['raised_amount_usd_y'].fillna(final_df['raised_amount_usd_y'].mode()[0], inplace=True)\n",
    "final_df['funding_total_usd'].fillna(final_df['funding_total_usd'].mode()[0], inplace=True)\n",
    "final_df['Num_of_investors'].fillna(final_df['Num_of_investors'].mode()[0], inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4bc9517",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['status'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afaabd7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2738ff1f",
   "metadata": {},
   "source": [
    "# Remove operating status from the final dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10fc508d",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = final_df[final_df.status != 'operating']\n",
    "final_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8851ff4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b1d270",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.loc[final_df['permalink'] == '/organization/goot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc37bf4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_df['Num_of_investors'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89e44e0",
   "metadata": {},
   "source": [
    "## ADD label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78dff102",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['label'] = 0\n",
    "final_df.loc[final_df.status == 'ipo', 'label'] = 1 # add 1 to the label column with status ipo or acquired\n",
    "final_df.loc[final_df.status == 'acquired', 'label'] = 1\n",
    "\n",
    "final_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d53d192",
   "metadata": {},
   "source": [
    "## split data into train and test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36eb1fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "X = final_df.drop(columns=['label'])\n",
    "y = final_df['label']\n",
    "kf = KFold(n_splits=5)\n",
    "\n",
    "for train_index, test_index in kf.split(X): # 80 20 % split\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5191452a",
   "metadata": {},
   "source": [
    "## Work on train test and add new features, statistical analysis etc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ffb3984",
   "metadata": {},
   "source": [
    "# Replace first funding date which are null with the date of last funding to make sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7cd574b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[X_train['first_funding_at'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5f073e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test[X_test['first_funding_at'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e7fefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['first_funding_at']=np.where(X_train['permalink']==\"/organization/motionmetrics\",\"2014-09-01\",X_train['first_funding_at'])\n",
    "X_test['first_funding_at']=np.where(X_test['permalink']==\"/organization/topicmarks\",\"2011-03-18\",X_test['first_funding_at']) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a200d48a",
   "metadata": {},
   "source": [
    "# Replace founded at date with the first funding date where there is abnormal dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6105542",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['founded_at']=np.where(X_train['permalink']==\"/organization/rent2cash-com\",\"2014-01-01\",X_train['founded_at'])\n",
    "X_train['founded_at']=np.where(X_train['permalink']==\"/organization/livamp-2\",\"2014-09-21\",X_train['founded_at'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86649fec",
   "metadata": {},
   "source": [
    "# Scale funding duration to millions and thousands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b43535",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['funding_total_usd'] = pd.to_numeric(X_train['funding_total_usd'], errors='coerce')\n",
    "#median = filter_data['funding_total_usd'].median()\n",
    "#filter_data['funding_total_usd'].fillna(median,inplace = True)\n",
    "\n",
    "#companies.info()\n",
    "\n",
    "X_train['fundind_total_k$'] = X_train['funding_total_usd']/1000\n",
    "X_train['funding_total_m$'] = X_train['funding_total_usd']/1000000\n",
    "X_train['funding_total_b$'] = X_train['funding_total_usd']/1000000000\n",
    "X_train.info()\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ad934a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test['fundind_total_k$'] = X_test['funding_total_usd']/1000\n",
    "X_test['funding_total_m$'] = X_test['funding_total_usd']/1000000\n",
    "X_test['funding_total_b$'] = X_test['funding_total_usd']/1000000000\n",
    "#X_train.info()\n",
    "#X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd05306d",
   "metadata": {},
   "source": [
    "# Adding new features to the dataset train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f63409d",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1=pd.to_datetime(X_train['first_funding_at'], errors = 'coerce')\n",
    "\n",
    "#t2 = pd.to_datetime(combined_company_investment_acquisition_rounds['last_funding_at'])\n",
    "t2=pd.to_datetime(X_train['last_funding_at'], errors = 'coerce')\n",
    "\n",
    "X_train['funding_duration']=t2-t1\n",
    "X_train['funding_duration_days']=X_train['funding_duration'].dt.days  ## This takes care of the duratrion that will remove \"days\" word in funding_duration column\n",
    "\n",
    "#company_investment_acquisition_rounds['funding_duration_year']=company_investment_acquisition_rounds['funding_duration'].astype('timedelta64[Y]') # use this when you want to see Year in as 0.0 when month is less than 12 becuase if less than 12 then year get displayed as 0.0\n",
    "X_train['funding_duration_year']=X_train['funding_duration'].dt.days/364.0   # use this when you want to see year as 0.6 for months less than 12 \n",
    "\n",
    "#company_investment_acquisition_rounds['funding_duration_month']=company_investment_acquisition_rounds['funding_duration'].astype('timedelta64[M]') # use this when you want to see 0.0 for month when days <30\n",
    "#company_investment_acquisition_rounds['funding_duration_month']=(company_investment_acquisition_rounds['funding_duration_year'])*364.0/30.0   # use this to see 0.034 as month when days <30\n",
    "X_train['funding_duration_month']=(X_train['funding_duration_days'])/30.0   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1120ed21",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1=pd.to_datetime(X_test['first_funding_at'], errors = 'coerce')\n",
    "\n",
    "#t2 = pd.to_datetime(combined_company_investment_acquisition_rounds['last_funding_at'])\n",
    "t2=pd.to_datetime(X_test['last_funding_at'], errors = 'coerce')\n",
    "\n",
    "X_test['funding_duration']=t2-t1\n",
    "X_test['funding_duration_days']=X_test['funding_duration'].dt.days  ## This takes care of the duratrion that will remove \"days\"\n",
    "\n",
    "#['funding_duration_year']=['funding_duration'].astype('timedelta64[Y]') # \n",
    "X_test['funding_duration_year']=X_test['funding_duration'].dt.days/364.0   # use \n",
    "\n",
    "X_test['funding_duration_month']=(X_test['funding_duration_days'])/30.0   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aba7e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = pd.DatetimeIndex(X_train['first_funding_at']).year\n",
    "p2 = pd.DatetimeIndex(X_train['last_funding_at']).year\n",
    "X_train['Avg_duration_of_funding']=p2-p1\n",
    "temp = X_train['Avg_duration_of_funding'] /2\n",
    "X_train['Avg_funding_in_year'] = temp\n",
    "\n",
    "#df['funding_duration'] = df['first_funding_at'] - df['last_funding_at']\n",
    "#df['first_funding_at_UTC'] = t1.astype(int)\n",
    "#df['last_funding_at_UTC'] = t2.astype(int)\n",
    "#filter_data.info()\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faab86c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = pd.DatetimeIndex(X_test['first_funding_at']).year\n",
    "p2 = pd.DatetimeIndex(X_test['last_funding_at']).year\n",
    "X_test['Avg_duration_of_funding']=p2-p1\n",
    "temp = X_test['Avg_duration_of_funding'] /2\n",
    "X_test['Avg_funding_in_year'] = temp\n",
    "\n",
    "#df['funding_duration'] = df['first_funding_at'] - df['last_funding_at']\n",
    "#df['first_funding_at_UTC'] = t1.astype(int)\n",
    "#df['last_funding_at_UTC'] = t2.astype(int)\n",
    "#filter_data.info()\n",
    "#X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b999d274",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[[\"founded_at_year\", \"founded_at_month\", \"founded_at_day\"]] = X_train[\"founded_at\"].str.split(\"-\", expand = True)\n",
    "#print(\"\\nNew DataFrame:\")\n",
    "X_train[[\"first_funding_year\", \"first_funding_month\", \"first_funding_day\"]] = X_train[\"first_funding_at\"].str.split(\"-\", expand = True)\n",
    "\n",
    "X_train[[\"last_funding_year\", \"last_funding_month\", \"last_funding_day\"]] = X_train[\"last_funding_at\"].str.split(\"-\", expand = True)\n",
    "\n",
    "X_train[[\"funded_year\", \"funded_month\", \"funded_day\"]] = X_train[\"funded_at_y\"].str.split(\"-\", expand = True)\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dfa37f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test[[\"founded_at_year\", \"founded_at_month\", \"founded_at_day\"]] = X_test[\"founded_at\"].str.split(\"-\", expand = True)\n",
    "#print(\"\\nNew DataFrame:\")\n",
    "X_test[[\"first_funding_year\", \"first_funding_month\", \"first_funding_day\"]] = X_test[\"first_funding_at\"].str.split(\"-\", expand = True)\n",
    "\n",
    "X_test[[\"last_funding_year\", \"last_funding_month\", \"last_funding_day\"]] = X_test[\"last_funding_at\"].str.split(\"-\", expand = True)\n",
    "\n",
    "X_test[[\"funded_year\", \"funded_month\", \"funded_day\"]] = X_test[\"funded_at_y\"].str.split(\"-\", expand = True)\n",
    "\n",
    "#X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eddc3f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['founded_at_day'] = pd.to_numeric(X_train['founded_at_day'], errors='coerce')\n",
    "X_train['founded_at_month'] = pd.to_numeric(X_train['founded_at_month'], errors='coerce')\n",
    "X_train['founded_at_year'] = pd.to_numeric(X_train['founded_at_year'], errors='coerce')\n",
    "\n",
    "\n",
    "X_train['first_funding_day'] = pd.to_numeric(X_train['first_funding_day'], errors='coerce')\n",
    "X_train['first_funding_month'] = pd.to_numeric(X_train['first_funding_month'], errors='coerce')\n",
    "X_train['first_funding_year'] = pd.to_numeric(X_train['first_funding_year'], errors='coerce')\n",
    "\n",
    "\n",
    "X_train['last_funding_day'] = pd.to_numeric(X_train['last_funding_day'], errors='coerce')\n",
    "X_train['last_funding_month'] = pd.to_numeric(X_train['last_funding_month'], errors='coerce')\n",
    "X_train['last_funding_year'] = pd.to_numeric(X_train['last_funding_year'], errors='coerce')\n",
    "\n",
    "X_train['funded_year'] = pd.to_numeric(X_train['funded_year'], errors='coerce')\n",
    "X_train['funded_month'] = pd.to_numeric(X_train['funded_month'], errors='coerce')\n",
    "X_train['funded_day'] = pd.to_numeric(X_train['funded_day'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4062e892",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test['founded_at_day'] = pd.to_numeric(X_test['founded_at_day'], errors='coerce')\n",
    "X_test['founded_at_month'] = pd.to_numeric(X_test['founded_at_month'], errors='coerce')\n",
    "X_test['founded_at_year'] = pd.to_numeric(X_test['founded_at_year'], errors='coerce')\n",
    "\n",
    "\n",
    "X_test['first_funding_day'] = pd.to_numeric(X_test['first_funding_day'], errors='coerce')\n",
    "X_test['first_funding_month'] = pd.to_numeric(X_test['first_funding_month'], errors='coerce')\n",
    "X_test['first_funding_year'] = pd.to_numeric(X_test['first_funding_year'], errors='coerce')\n",
    "\n",
    "\n",
    "X_test['last_funding_day'] = pd.to_numeric(X_test['last_funding_day'], errors='coerce')\n",
    "X_test['last_funding_month'] = pd.to_numeric(X_test['last_funding_month'], errors='coerce')\n",
    "X_test['last_funding_year'] = pd.to_numeric(X_test['last_funding_year'], errors='coerce')\n",
    "\n",
    "X_test['funded_year'] = pd.to_numeric(X_test['funded_year'], errors='coerce')\n",
    "X_test['funded_month'] = pd.to_numeric(X_test['funded_month'], errors='coerce')\n",
    "X_test['funded_day'] = pd.to_numeric(X_test['funded_day'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773db912",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "\n",
    "today = date.today()\n",
    "a1 =X_train['founded_at_year']\n",
    "\n",
    "X_train['Age of Company'] = today.year - a1\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0464fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "today = date.today()\n",
    "a1 =X_test['founded_at_year']\n",
    "\n",
    "X_test['Age of Company'] = today.year - a1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66de970b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['raised_amount_k$'] = X_train['funding_total_usd']/1000\n",
    "X_train['raised_amount_m$'] = X_train['raised_amount_usd_y']/1000000\n",
    "X_train['raised_amount_b$'] = X_train['raised_amount_usd_y']/1000000000\n",
    "X_train.info()\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0aa249e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test['raised_amount_k$'] = X_test['funding_total_usd']/1000\n",
    "X_test['raised_amount_m$'] = X_test['raised_amount_usd_y']/1000000\n",
    "X_test['raised_amount_b$'] = X_test['raised_amount_usd_y']/1000000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e019a719",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[X_train['investor_name'].isnull()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b026f1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "todaydate=datetime.today().date().strftime('%Y-%m-%d')\n",
    "X_train['todaydate_conv'] = pd.to_datetime(todaydate)\n",
    "\n",
    "X_train['founded_at_conv'] = pd.to_datetime(X_train[\"founded_at\"], errors='coerce')\n",
    "\n",
    "X_train['Age_of_company_month'] = (X_train['todaydate_conv'] - X_train['founded_at_conv'])/np.timedelta64(1, 'M')\n",
    "\n",
    "X_train.isnull().sum()  #since there is only one blank value in Age_of_company_month i will do the below to conver to int\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0b5fec",
   "metadata": {},
   "source": [
    "# create labels temporary to add new features based on label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead3dc60",
   "metadata": {},
   "outputs": [],
   "source": [
    "combine = pd.concat([X_train, X_test], axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec23d0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['label'] = 0\n",
    "X_train.loc[X_train.status == 'ipo', 'label'] = 1 # add 1 to the label column with status ipo or acquired\n",
    "X_train.loc[X_train.status == 'acquired', 'label'] = 1\n",
    "\n",
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711ee695",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test['label'] = 0\n",
    "X_test.loc[X_test.status == 'ipo', 'label'] = 1 # add 1 to the label column with status ipo or acquired\n",
    "X_test.loc[X_test.status == 'acquired', 'label'] = 1\n",
    "\n",
    "#X_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb8723c",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_split = X_train[\"category_list\"].str.split(\"|\", n = 1, expand = True)\n",
    "\n",
    "#category_split = X_test[\"category_list\"].str.split(\"|\", n = 1, expand = True)\n",
    "#print(category_split)\n",
    "#print(category_split)\n",
    "X_train[\"category_1\"] = category_split[0]\n",
    "\n",
    "#X_test[\"category_1\"] = category_split[0]\n",
    "\n",
    "X_train.head()\n",
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1bee31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_split1 = X_test[\"category_list\"].str.split(\"|\", n = 1, expand = True)\n",
    "X_test[\"category_1\"] = category_split1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07866cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.rename(columns={'Domain': 'company domain', 'funding_round_code_x': 'funding_round_code',\n",
    "                                    'funding_round_type_y': 'funding_round_type','raised_amount_usd_y': 'raised_amount_usd'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f742e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test.rename(columns={'Domain': 'company domain', 'funding_round_code_x': 'funding_round_code',\n",
    "                                    'funding_round_type_y': 'funding_round_type','raised_amount_usd_y': 'raised_amount_usd'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf81837",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371f9621",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['past_year'] = X_train['founded_at_year']-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1337fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head(30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5f5e5d",
   "metadata": {},
   "source": [
    "### EDA on X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41860cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "plt.xlim(0, 300)\n",
    "sns.distplot(X_train['Age_of_company_month'], hist=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318d928b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "plt.xlim(-1000, 4000)\n",
    "sns.distplot(X_train['funding_duration_days'], hist=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd926616",
   "metadata": {},
   "outputs": [],
   "source": [
    "variable=[\"first_funding_year\",\"last_funding_year\",\"founded_at_year\"]\n",
    "\n",
    "plt.figure(figsize=(17,3),dpi=100)\n",
    "for i in range(len(variable)):\n",
    "    plt.subplot(1,3,i+1)\n",
    "    plt.title(\"{}\". format(variable[i]))\n",
    "    sns.distplot(X_train[variable[i]], color=\"orange\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126089b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure size\n",
    "plt.figure(figsize=(6,6))\n",
    "\n",
    "# Pie plot\n",
    "X_train['label'].value_counts().plot.pie(explode=[0.1,0.1], autopct='%1.1f%%', shadow=True, textprops={'fontsize':16}).set_title(\"Status Distribution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575b1102",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure size\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.xlim(0, 800)\n",
    "# Histogram\n",
    "sns.histplot(data=X_train, x='Age_of_company_month', hue='label', binwidth=10, kde=True)\n",
    "\n",
    "# Aesthetics\n",
    "plt.title('Age distribution')\n",
    "plt.xlabel('Age (in months)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5f59dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Age of Company\n",
    "# Figure size\n",
    "plt.figure(figsize=(10,4))\n",
    "# plt.xlim(0, 800)\n",
    "# Histogram\n",
    "sns.histplot(data=X_train, x='Age of Company', hue='label', binwidth=10, kde=True)\n",
    "\n",
    "# Aesthetics\n",
    "plt.title('Age distribution')\n",
    "plt.xlabel('Age (in years)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71c7dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,3),dpi=100)\n",
    "plt.subplot(1,3,1)\n",
    "sns.scatterplot(X_train[\"first_funding_year\"],X_train[\"last_funding_year\"], label=\"first&last funding\", palette=\"Greens\")\n",
    "#sns.scatterplot(df[\"age_first_milestone_year\"], df[\"age_last_milestone_year\"], label=\"first&last milestone\", palette=\"Blues\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.xlim(1900, 2100)\n",
    "sns.distplot(X_train[\"first_funding_year\"], label=\"first_funding\")\n",
    "sns.distplot(X_train[\"last_funding_year\"], label=\"last_funding\")\n",
    "sns.distplot(X_train[\"founded_at_year\"], label=\"first_milestone\")\n",
    "#sns.distplot(df[\"age_last_milestone_year\"], label=\"last_milestone\")\n",
    "plt.xlabel(\"first_funding, last_funding, first_milestone, last_milestone\")\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8119cf68",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install plotly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4f8863",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import plotly.graph_objs as go\n",
    "# visualization styling\n",
    "plt.style.use('ggplot')\n",
    "choropleth_map = go.Figure(\n",
    "    data = {\n",
    "        'type':'choropleth',\n",
    "        'locationmode':'USA-states',        \n",
    "        'locations':list(X_train.state_code.value_counts().index),\n",
    "        'colorscale':'Reds',            \n",
    "        'z':list(X_train.state_code.value_counts().values),   \n",
    "#         'title': 'State Code'รท\n",
    "        },     \n",
    "    layout = {\n",
    "      'geo':{\n",
    "          'scope':'usa'\n",
    "      }  \n",
    "    })\n",
    "choropleth_map.update_layout(\n",
    "    title_text = '1. State Code',\n",
    ")\n",
    "choropleth_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5d3b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['mathtext.fontset'] = 'stix'\n",
    "plt.rcParams['font.serif'] = ['Times New Roman']\n",
    "plt.rcParams[\"figure.figsize\"] = (14,5) \n",
    "plt.rcParams[\"figure.dpi\"] = 130  \n",
    "\n",
    "plt.title(\"8. category_code\",{'fontsize':16,\n",
    "        'fontweight':\"bold\"})\n",
    "\n",
    "category = X_train['category_1'].value_counts()\n",
    "\n",
    "plt.xticks(rotation=90)\n",
    "sns.barplot(x=category.index,y=category.values,palette = 'ocean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d88f88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.to_csv(\"X_train_datafile_generation_new_features_08.28.22.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0fe84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.to_csv(\"X_test_datafile_generation_new_features_08.28.22.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2188ab2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1 = pd.read_csv(\"x_train_past_current_future_11.25.22.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cfbc2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test1 = pd.read_csv(\"x_test_with_current_future_past_11.15.22.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794500b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5df7c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8052fdb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1.rename(columns = {'fundind_total_k':'fundind_total_k$','funding_total_m': 'funding_total_m$','funding_total_b':'funding_total_b$','Sum_RaisedAmt_Label1':'sum_investor_raisedAmt_sucess',\n",
    "                             'Sum_RaisedAmt_Label0': 'sum_investor_raisedAmt_failure',\n",
    "                             'TotalLabel1':'no_of_successful_comp','TotalLabel0':'no_of_failed_comp','TotalRecords':'total_companies',\n",
    "                            'SuccessRate_by_company' : 'percentage_of_success_rate_by_comp','FailureRate': 'percentage_of_failure_rate_by_comp'\n",
    "                            ,'SuccessByAmount':'percentage_of_success_rate_by_USD','raised_amount_k':'raised_amount_k$','raised_amount_m':'raised_amount_m$','raised_amount_b':'raised_amount_b$'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbc43a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test1.rename(columns = {'fundind_total_k':'fundind_total_k$','funding_total_m': 'funding_total_m$','funding_total_b':'funding_total_b$','Sum_RaisedAmt_Label1':'sum_investor_raisedAmt_sucess',\n",
    "                             'Sum_RaisedAmt_Label0': 'sum_investor_raisedAmt_failure',\n",
    "                             'TotalLabel1':'no_of_successful_comp','TotalLabel0':'no_of_failed_comp','TotalRecords':'total_companies',\n",
    "                            'SuccessRate_by_company' : 'percentage_of_success_rate_by_comp','FailureRate': 'percentage_of_failure_rate_by_comp'\n",
    "                            ,'SuccessByAmount':'percentage_of_success_rate_by_USD','raised_amount_k':'raised_amount_k$','raised_amount_m':'raised_amount_m$','raised_amount_b':'raised_amount_b$'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8a052c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452297d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_new = X_train1.drop(columns=['name', 'homepage_url', 'status', 'state_code',\n",
    "                      'funded_at_y','first_funding_at','last_funding_at','funding_duration',\n",
    "                                 'investor_country_code','state_code','region','city','FlagForCat1_Past',\n",
    "                                  'FlagForCat1_Current','FlagForCat1_Future','CountofCompanies','category_list',\n",
    "                             'investor_permalink','founded_at','Previous_2Year','Next_2Year','Past_3Year','Future_2Year','StartYear',\n",
    "                                    'Current_CountOfTop15','Future_CountOfTop15','Past_CountOfTop15'])\n",
    "\n",
    "X_train_new.info()  #10668"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33c3326",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_new = X_test1.drop(columns=['name', 'homepage_url', 'status', 'state_code',\n",
    "                      'funded_at_y','first_funding_at','last_funding_at','funding_duration',\n",
    "                                 'investor_country_code','state_code','region','city','FlagForCat1_Past',\n",
    "                                  'FlagForCat1_Current','FlagForCat1_Future','CountofCompanies','category_list',\n",
    "                             'investor_permalink','founded_at','Previous_2Year','Next_2Year','Past_3Year','Future_2Year','EndYear',\n",
    "                                    'Current_CountOfTop15','Future_CountOfTop15','Past_CountOfTop15'])\n",
    "\n",
    "X_test_new.info()  #2666"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745fe5ca",
   "metadata": {},
   "source": [
    "## Creating past current and future count of categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04dfc99",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Past count of categories\n",
    "sp = X_train_new.shape[0]\n",
    "# print(file.iloc[file.shape[0]-1,:])\n",
    "arr=[]\n",
    "for i in range(sp):\n",
    "    ans = X_train_new[(X_train_new.category_1 == X_train_new.iloc[i,:].category_1) & (X_train_new.founded_at_year <= (X_train_new.iloc[i,:].founded_at_year-3))]\n",
    "    #print(ans.shape[0])\n",
    "    arr.append(ans.shape[0])\n",
    "#print(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43606db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(arr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302a8ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(arr, columns =['past_count'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf52078",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(drop=True)\n",
    "X_train_new.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15ce71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_new.index = df.index\n",
    "#df2 =pd.concat([X_train, df], axis = 1)\n",
    "train_set = pd.concat([X_train_new.reset_index(drop=True), df.reset_index(drop=True)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244ddc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab03b2f",
   "metadata": {},
   "source": [
    "## Create Future Count of category for train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3172eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Future count of categories\n",
    "sf1 = train_set.shape[0]\n",
    "# print(file.iloc[file.shape[0]-1,:])\n",
    "arr2=[]\n",
    "for i in range(sf1):\n",
    "    future1 = train_set[(train_set.category_1 == train_set.iloc[i,:].category_1) & (train_set.founded_at_year >= (train_set.iloc[i,:].founded_at_year+3))]\n",
    "    #print(ans.shape[0])\n",
    "    arr2.append(future1.shape[0])\n",
    "#print(arr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0726b81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(arr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9718dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_future = pd.DataFrame(arr2, columns =['future_count'])\n",
    "train_df_future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb8643c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "train_df_future.reset_index(drop=True)\n",
    "train_set.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfe6b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "train_df_future.index = train_set.index\n",
    "#df2 =pd.concat([X_train, df], axis = 1)\n",
    "train_past_future_current = pd.concat([train_set.reset_index(drop=True), train_df_future.reset_index(drop=True)], axis=1)\n",
    "train_past_future_current"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d33283",
   "metadata": {},
   "source": [
    "## Past and Future test count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f7638e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Future count of categories\n",
    "sf1 = X_test_new.shape[0]\n",
    "# print(file.iloc[file.shape[0]-1,:])\n",
    "arr3=[]\n",
    "for i in range(sf1):\n",
    "    future = X_test_new[(X_test_new.category_1 == X_test_new.iloc[i,:].category_1) & (X_test_new.founded_at_year >= (X_test_new.iloc[i,:].founded_at_year+3))]\n",
    "    #print(ans.shape[0])\n",
    "    arr3.append(future.shape[0])\n",
    "#print(arr1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d8760b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(arr3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30f27cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame(arr3, columns =['future_count'])\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab503f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "test_df.reset_index(drop=True)\n",
    "X_test_new.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b27479e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_new.index = test_df.index\n",
    "#df2 =pd.concat([X_train, df], axis = 1)\n",
    "test_set = pd.concat([X_test_new.reset_index(drop=True), test_df.reset_index(drop=True)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce04562",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "test_set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08b1f3a",
   "metadata": {},
   "source": [
    "## Past count for test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3efdcf50",
   "metadata": {},
   "outputs": [],
   "source": [
    "## past count of categories\n",
    "spast = test_set.shape[0]\n",
    "# print(file.iloc[file.shape[0]-1,:])\n",
    "arr_p=[]\n",
    "for i in range(spast):\n",
    "    past = test_set[(test_set.category_1 == test_set.iloc[i,:].category_1) & (test_set.founded_at_year <= (test_set.iloc[i,:].founded_at_year-3))]\n",
    "    #print(ans.shape[0])\n",
    "    arr_p.append(past.shape[0])\n",
    "#print(arr_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6be2b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(arr_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e667e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_past = pd.DataFrame(arr_p, columns =['past_count'])\n",
    "test_past"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d34ba29",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "test_past.reset_index(drop=True)\n",
    "test_set.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714fa12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_past.index = test_set.index\n",
    "#df2 =pd.concat([X_train, df], axis = 1)\n",
    "test_past_future_current = pd.concat([test_set.reset_index(drop=True), test_past.reset_index(drop=True)], axis=1)\n",
    "test_past_future_current"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6262208d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_past_future_current['country_code'] = train_past_future_current['country_code'].astype('category')\n",
    "\n",
    "others = train_past_future_current['country_code'].value_counts().index[6:]\n",
    "label1 = 'other countries'\n",
    "\n",
    "train_past_future_current['country_code'] = train_past_future_current['country_code'].cat.add_categories([label1])\n",
    "train_past_future_current['country_code'] = train_past_future_current['country_code'].replace(others, label1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209cfa63",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_past_future_current['country_code'] = test_past_future_current['country_code'].astype('category')\n",
    "#X_test_new['country_code'] = X_test_new['country_code'].cat.add_categories([label1])\n",
    "test_past_future_current['country_code'] = train_past_future_current['country_code'].replace(others, label1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f087d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    " train_past_future_current.country_code.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd23441",
   "metadata": {},
   "outputs": [],
   "source": [
    " test_past_future_current.country_code.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7709d930",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_test['country_code'] = X_train['country_code'].cat.add_categories([label1])\n",
    "#X_test['country_code'] = X_train['country_code'].replace(others, label1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c760c055",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_test_new.country_code.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0daf8ba3",
   "metadata": {},
   "source": [
    "#  Keep the Top 4 domain and put the rest in Others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1452b5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_past_future_current['company_domain'] = train_past_future_current['company_domain'].astype('category')\n",
    "\n",
    "others1 = train_past_future_current['company_domain'].value_counts().index[4:]\n",
    "label3 = 'Others'\n",
    "\n",
    "train_past_future_current['company_domain'] = train_past_future_current['company_domain'].cat.add_categories([label3])\n",
    "train_past_future_current['company_domain'] = train_past_future_current['company_domain'].replace(others1, label3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149385e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_past_future_current['company_domain'] = test_past_future_current['company_domain'].astype('category')\n",
    "#X_test_new['country_code'] = X_test_new['country_code'].cat.add_categories([label1])\n",
    "test_past_future_current['company_domain'] = train_past_future_current['company_domain'].replace(others, label1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a909ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_past_future_current.company_domain.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce52b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_past_future_current.company_domain.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba876589",
   "metadata": {},
   "source": [
    "## Investor Names information ****************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09da52ae",
   "metadata": {},
   "source": [
    "## Get most occured investor names and convert them to one hot encoded values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27feca28",
   "metadata": {},
   "outputs": [],
   "source": [
    "null_cells = train_past_future_current[\"investor_name\"].isnull()\n",
    "train_past_future_current[\"investor_name\"] = train_past_future_current[\"investor_name\"].astype(str).mask(null_cells, np.NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833b02bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_past_future_current[\"investor_name\"].fillna('no_investor', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4067ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_common_investor = Counter(\" \".join(train_past_future_current[\"investor_name\"].str.lower()).split()).most_common(25)\n",
    "most_common_investor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60ad6e4",
   "metadata": {},
   "source": [
    "## create a list of most common investor names and add the rest to 'others'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138d5606",
   "metadata": {},
   "outputs": [],
   "source": [
    "toxx = ['Ventures','Capital','Partners','Fund','Venture','Group','Investment','Management','Technology','Equity','Angel','Startups','Bank']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544747ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,10668):\n",
    "    if any(ext in train_past_future_current['investor_name'][i] for ext in toxx):\n",
    "        train_past_future_current['investor_name'][i] = train_past_future_current['investor_name'][i]\n",
    "    else:\n",
    "        train_past_future_current['investor_name'][i] = 'other_investors'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32aefb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "null_cells = train_past_future_current[\"investor_name\"].isnull()\n",
    "train_past_future_current[\"investor_name\"] = train_past_future_current[\"investor_name\"].astype(str).mask(null_cells, np.NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbd7ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_past_future_current[\"investor_name\"].fillna('no_investor', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb35b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,2666):\n",
    "    if any(ext in test_past_future_current['investor_name'][i] for ext in toxx):\n",
    "        test_past_future_current['investor_name'][i] = test_past_future_current['investor_name'][i]\n",
    "    else:\n",
    "        test_past_future_current['investor_name'][i] = 'other_investors'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e259c323",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_past_future_current['investor_name'].head(45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a604a2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_past_future_current['investor_name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41df753a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_past_future_current.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381c1e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_past_future_current.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9f1bfd",
   "metadata": {},
   "source": [
    "## one hot encoded investor names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9ba73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ############################# to convert most common investor names into one hot encoded columns ########################\n",
    "\n",
    "\n",
    "\n",
    "toxic = ['ventures','capital','partners','fund','venture','group','investment','management','technology','equity','angel','startups','bank','other_investors']\n",
    "\n",
    "#df = pd.DataFrame({'text':['You look horrible','You are good','you are bad and disguisting']})\n",
    "\n",
    "train = pd.concat([train_past_future_current,pd.DataFrame(columns=toxic)],ignore_index=True, sort=False)\n",
    "train.replace(np.nan, 0.0)\n",
    "\n",
    "samp_col = train['investor_name'].str.lower()\n",
    "\n",
    "samp = samp_col.str.split().apply(lambda x : [i for i in toxic if i in x])\n",
    "\n",
    "for i,j in enumerate(samp):\n",
    "    for k in j:\n",
    "        train.loc[i,k] = 1.0\n",
    "\n",
    "\n",
    "train.head(40)\n",
    "\n",
    "# main[['ventures','capital','partners','fund','venture','group','investment','management','technology','equity','angel','startups','bank','other_investors']] = main[['ventures','capital','partners','fund','venture','group','investment','management','technology','equity','angel','startups','bank','other_investors']].cat.add_categories('Null')\n",
    "# main['categorical_column'].fillna('Null', inplace=True)\n",
    "\n",
    "train.replace(np.nan, 0.0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642d0d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd. set_option('display.max_columns', 500)\n",
    "# train.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b431a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa5f5e8a",
   "metadata": {},
   "source": [
    "## test set one hot encoded investor names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbf53b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#toxic = ['ventures','capital','partners','fund','venture','group','investment','management','technology','equity','angel','startups','bank','other_investors']\n",
    "\n",
    "\n",
    "\n",
    "test = pd.concat([test_past_future_current,pd.DataFrame(columns=toxic)],ignore_index=True, sort=False)\n",
    "test.replace(np.nan, 0.0)\n",
    "\n",
    "samp_cols = test['investor_name'].str.lower()\n",
    "\n",
    "samps = samp_cols.str.split().apply(lambda x : [i for i in toxic if i in x])\n",
    "\n",
    "for i,j in enumerate(samps):\n",
    "    for k in j:\n",
    "        test.loc[i,k] = 1.0\n",
    "\n",
    "test.replace(np.nan, 0.0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c488aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042a2379",
   "metadata": {},
   "source": [
    "# tokenize category to fit into the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f515f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.datasets import fetch_openml\n",
    "#from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics \n",
    "from sklearn import ensemble\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_curve, roc_auc_score, auc, f1_score\n",
    "from scipy import interp\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "%matplotlib inline \n",
    "\n",
    "# X = main.drop(columns = ['label'])\n",
    "# y = main['label']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d0b575",
   "metadata": {},
   "source": [
    "# tokenize category and count occurances using count vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c4cd25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(stop_words ='english',analyzer='word')\n",
    "#cv = CountVectorizer(parameters desired)\n",
    "\n",
    "train_1 = vectorizer.fit_transform(train['category_1'])\n",
    "train_x = pd.DataFrame(train_1.toarray(), columns = vectorizer.get_feature_names()) \n",
    "test_1 = vectorizer.transform(test['category_1'])\n",
    "test_x = pd.DataFrame(test_1.toarray(), columns = vectorizer.get_feature_names()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eabf81be",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79cb58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa849576",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.reset_index(drop=True, inplace=True)\n",
    "res = pd.concat([train, train_x], axis = 1)\n",
    "res.head()\n",
    "X_train_res =res.drop(columns=['permalink','investor_name','category_1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ac01f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_res.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91fb7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.reset_index(drop=True, inplace=True)\n",
    "\n",
    "reset = pd.concat([test, test_x], axis = 1)\n",
    "#res.head()\n",
    "X_test_res =reset.drop(columns=['permalink','investor_name','category_1','label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e458eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_res.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd41b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_res.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002a9457",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=X_train_res['label'].copy().astype(int) # y is label\n",
    "X=X_train_res.drop('label', axis=1).copy() # now X is new X_train, X_test is as it is (X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9609cb",
   "metadata": {},
   "source": [
    "## One hot Encode Country_code, company_domain_funding_round_code, funding round type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3860545",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "encoder=OneHotEncoder(sparse=False)\n",
    "\n",
    "\n",
    "\n",
    "train_X_encoded = pd.DataFrame (encoder.fit_transform(X[['country_code','company_domain','funding_round_code','funding_round_type']]))\n",
    "train_X_encoded.columns = encoder.get_feature_names(['country_code','company_domain','funding_round_code','funding_round_type'])\n",
    "\n",
    "test_X_encoded = pd.DataFrame (encoder.transform(X_test_res[['country_code','company_domain','funding_round_code','funding_round_type']]))\n",
    "\n",
    "test_X_encoded.columns = encoder.get_feature_names(['country_code','company_domain','funding_round_code','funding_round_type'])\n",
    "\n",
    "X_test_res.drop(['country_code','company_domain','funding_round_code','funding_round_type'] ,axis=1, inplace=True)\n",
    "\n",
    "\n",
    "OH_X_test = pd.concat([X_test_res, test_X_encoded ], axis=1)\n",
    "X.drop(['country_code','company_domain','funding_round_code','funding_round_type'] ,axis=1, inplace=True)\n",
    "OH_X_train= pd.concat([X, train_X_encoded ], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ab5cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "OH_X_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5e4737",
   "metadata": {},
   "outputs": [],
   "source": [
    "OH_X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a7a189",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = OH_X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530bf355",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = OH_X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6c6a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.loc[:,~X.columns.duplicated()].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8016f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test.loc[:,~X_test.columns.duplicated()].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc8d320",
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_X = pd.concat([X, X_test], axis=0).reset_index(drop=True)\n",
    "#df = df.loc[~df.index.duplicated(keep='first')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7ab98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1a4a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_y = pd.concat([y, y_test], axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0015ca1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = combine_X\n",
    "y = [combine_y]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09e4eca",
   "metadata": {},
   "source": [
    "## Sklearn model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0516b923",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sklearn\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, recall_score, precision_score, f1_score\n",
    "from sklearn.metrics import roc_auc_score, plot_confusion_matrix, plot_roc_curve, roc_curve\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "##import eli5\n",
    "#from eli5.sklearn import PermutationImportance\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# Models\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import model_selection\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753bdd9b",
   "metadata": {},
   "source": [
    "## Train test split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015025ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-validation split\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X,y,stratify=y,train_size=0.8,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c28e54",
   "metadata": {},
   "source": [
    "## Prepare configuration for cross validation test harness models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae75d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare configuration for cross validation test harness\n",
    "seed = 7\n",
    "# prepare models\n",
    "models = []\n",
    "models.append(('LR', LogisticRegression(random_state = 42, max_iter = 10**6)))\n",
    "#models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('KNN', KNeighborsClassifier(n_neighbors = 91)))\n",
    "models.append(('DT', DecisionTreeClassifier(random_state=42)))\n",
    "#models.append(('NB', GaussianNB()))\n",
    "models.append(('XGBoost', XGBClassifier(use_label_encoder =False, eval_metric='mlogloss')))\n",
    "models.append(('AdaBoost', AdaBoostClassifier(n_estimators=100, random_state=0)))\n",
    "models.append(('RFC-100',RandomForestClassifier(n_estimators = 100,random_state=521)))\n",
    "models.append(('RFC-200',RandomForestClassifier(n_estimators = 200,random_state=521)))\n",
    "models.append\n",
    "# evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "scoring = 'accuracy'\n",
    "for name, model in models:\n",
    "    kfold = model_selection.RepeatedKFold(n_splits=5, n_repeats=5, random_state=1)\n",
    "    cv_results = model_selection.cross_val_score(model, X, y, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)\n",
    "# boxplot algorithm comparison\n",
    "fig = plt.figure()\n",
    "fig.suptitle('Algorithm Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "plt.grid()\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46fea2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig('Algorithm_comparison.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33e3b3c",
   "metadata": {},
   "source": [
    "## Method 1 for model testing - using confusion matrix, accuracy and ROC curve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52133947",
   "metadata": {},
   "source": [
    "## Another method 2 for modeling and building prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f69c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics \n",
    "from sklearn import ensemble\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_curve, roc_auc_score, auc, f1_score\n",
    "from scipy import interp\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be83a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################LR model ##########################################\n",
    "\n",
    "from sklearn.model_selection import KFold \n",
    "kf = RepeatedKFold(n_splits=10, n_repeats=5, random_state=1)\n",
    "accuracy_model_1=[]\n",
    "\n",
    "#Notes\n",
    "#The first n_samples(11343) % n_splits(5) folds have size n_samples // n_splits + 1\n",
    "#, other folds have size n_samples // n_splits, where n_samples is the number of samples.\n",
    "\n",
    "#cm = confusion_matrix(y_test, y1_pred)\n",
    "#sns.heatmap(cm, annot = True)\n",
    "#plt.show()\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "   # print(\"Train:\", train_index, \"Validation:\",test_index)\n",
    "    X_train, X_test = X[train_index], X[test_index] \n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    \n",
    "    model_1 = LogisticRegression(random_state=42, max_iter= 10**4)\n",
    "    model_1.fit(X_train, y_train)\n",
    "    y1_pred = model_1.predict(X_test)\n",
    "    accuracy_model_1.append(accuracy_score(y_test, y1_pred))\n",
    "print(accuracy_model_1)\n",
    "#cm = confusion_matrix(y_test, y1_pred)\n",
    "#sns.heatmap(cm, annot = True)\n",
    "#plt.show()\n",
    "print (\"Avg accuracy for LR \", np.array(accuracy_model_1).mean())\n",
    "cm = confusion_matrix(y_test, y1_pred)\n",
    "sns.heatmap(cm, annot = True, fmt = 'g')\n",
    "plt.show()\n",
    "\n",
    "print(classification_report(y_test,y1_pred))\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test,y1_pred)\n",
    "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "print(\"roc_auc\",roc_auc)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8ee1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################ RF model 100 ##########################################\n",
    "\n",
    "from sklearn.model_selection import KFold \n",
    "kf = RepeatedKFold(n_splits=10, n_repeats=5, random_state=1)\n",
    "accuracy_model_2=[]\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "   # print(\"Train:\", train_index, \"Validation:\",test_index)\n",
    "    X_train, X_test = X[train_index], X[test_index] \n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    \n",
    "    #model_2 = sklearn.ensemble.RandomForestClassifier(bootstrap=False, max_depth=12, min_samples_leaf=100, min_samples_split=20,\n",
    "                      # n_estimators=100,criterion='entropy',n_jobs=1000,max_leaf_nodes=100,max_features='auto', random_state = 521)\n",
    "    model_2 = RandomForestClassifier(n_estimators=100, random_state=521)\n",
    "    model_2.fit(X_train, y_train)\n",
    "    y2_pred = model_2.predict(X_test)\n",
    "    accuracy_model_2.append(accuracy_score(y_test, y2_pred))\n",
    "\n",
    "print(accuracy_model_2)\n",
    "cm = confusion_matrix(y_test, y2_pred)\n",
    "sns.heatmap(cm, annot = True, fmt = 'g')\n",
    "plt.show()    \n",
    " \n",
    "print(classification_report(y_test,y2_pred))\n",
    "print (\"Avg accuracy for RF \", np.array(accuracy_model_2).mean())\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test,y2_pred)\n",
    "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "print(\"roc_auc\",roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c4358a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold \n",
    "kf = RepeatedKFold(n_splits=5, n_repeats=5, random_state=1)\n",
    "accuracy_model_ft=[]\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "   # print(\"Train:\", train_index, \"Validation:\",test_index)\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index] \n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    \n",
    "    #model_2 = sklearn.ensemble.RandomForestClassifier(bootstrap=False, max_depth=12, min_samples_leaf=100, min_samples_split=20,\n",
    "                      # n_estimators=100,criterion='entropy',n_jobs=1000,max_leaf_nodes=100,max_features='auto', random_state = 521)\n",
    "    model_ft = RandomForestClassifier(n_estimators=200, random_state=521)\n",
    "    model_ft.fit(X_train, y_train)\n",
    "#     y2_pred = model_ft.predict(X_test)\n",
    "#     accuracy_model_ft.append(accuracy_score(y_test, y2_pred))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938c0438",
   "metadata": {},
   "source": [
    "# Feature Importance Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d3c704",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    " \n",
    "importances = model_ft.feature_importances_\n",
    "#\n",
    "# Sort the feature importance in descending order\n",
    "#\n",
    "sorted_indices = np.argsort(importances)[::-1]\n",
    " \n",
    "feat_labels = combine_X.columns[1:]\n",
    " \n",
    "for f in range(X_train.shape[1]):\n",
    "    print(\"%2d) %-*s %f\" % (f + 1, 30,\n",
    "                            feat_labels[sorted_indices[f]],\n",
    "                            importances[sorted_indices[f]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09004556",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = pd.DataFrame(data={\n",
    "    'Attribute': combine_X.columns,\n",
    "    'Importance': model_ft.feature_importances_\n",
    "})\n",
    "importances = importances.sort_values(by='Importance', ascending=False)\n",
    "plt.bar(x=importances['Attribute'], height=importances['Importance'], color='#087E8B')\n",
    "plt.title('Feature importances obtained from coefficients', size=20)\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcad4ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_importances = pd.Series(model_ft.feature_importances_, index=combine_X.columns)\n",
    "feat_importances.nlargest(55) #.plot(kind='barh')\n",
    "feature_n = feat_importances.nlargest(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047b6bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feat =feature_n.to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513f7877",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feat.index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169f88f6",
   "metadata": {},
   "source": [
    "# Random Forest Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3eb0f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tree = RandomForestClassifier(max_depth = 3, n_estimators=10, random_state=521)\n",
    "model_tree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f66041f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(model_tree.estimators_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13c2188",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "_ = tree.plot_tree(model_tree.estimators_[0], filled=True,fontsize=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03154c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, make_scorer\n",
    "# Custom scorer for cross validation\n",
    "scorer = make_scorer(f1_score, greater_is_better=True, average = 'macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248a94f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "# Create a model for feature selection\n",
    "estimator = RandomForestClassifier(random_state = 10, n_estimators = 100, max_depth = 3,  n_jobs = -1)\n",
    "\n",
    "# Create the object\n",
    "selector = RFECV(estimator, step = 1, cv = 3, scoring= scorer, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f22e457",
   "metadata": {},
   "outputs": [],
   "source": [
    "selector.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3e7cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "rankings = pd.DataFrame({'feature': list(X_train.columns), 'rank': list(selector.ranking_)}).sort_values('rank')\n",
    "rankings.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800897da",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_selected = selector.transform(X_train)\n",
    "test_selected = selector.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2ddce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = X_train.columns[np.where(selector.ranking_==1)]\n",
    "train_selected = pd.DataFrame(train_selected, columns = selected_features)\n",
    "test_selected = pd.DataFrame(test_selected, columns = selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1984ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6269a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine_X.columns[300:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d524282",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "plotdata = pd.DataFrame({\n",
    "\n",
    "    \"Investment\":[50,32,36],\n",
    "\n",
    "    \"Business\":[30,48,46],\n",
    "\n",
    "    \"Market\":[20,20,18]},\n",
    "    \n",
    "    index=[\"TOP 10\", \"TOP 25\", \"TOP 50\"])\n",
    "\n",
    "plotdata.plot(kind=\"bar\",figsize=(14, 7),fontsize = 13)\n",
    "\n",
    "\n",
    "plt.title(\"Top Feature Category\",fontsize = 14)\n",
    "\n",
    "#plt.xlabel(\"Feature Selection\")\n",
    "\n",
    "plt.ylabel(\"Percentage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fc1300",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################ RF model 200 trees ##########################################\n",
    "\n",
    "from sklearn.model_selection import KFold \n",
    "kf = RepeatedKFold(n_splits=10, n_repeats=5, random_state=1)\n",
    "accuracy_model_2=[]\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "   # print(\"Train:\", train_index, \"Validation:\",test_index)\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index] \n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    \n",
    "    #model_2 = sklearn.ensemble.RandomForestClassifier(bootstrap=False, max_depth=12, min_samples_leaf=100, min_samples_split=20,\n",
    "                      # n_estimators=100,criterion='entropy',n_jobs=1000,max_leaf_nodes=100,max_features='auto', random_state = 521)\n",
    "    model_2 = RandomForestClassifier(n_estimators=200, random_state=521)\n",
    "    model_2.fit(X_train, y_train)\n",
    "    y2_pred = model_2.predict(X_test)\n",
    "    accuracy_model_2.append(accuracy_score(y_test, y2_pred))\n",
    "\n",
    "print(accuracy_model_2)\n",
    "cm = confusion_matrix(y_test, y2_pred)\n",
    "sns.heatmap(cm, annot = True, fmt = 'g')\n",
    "plt.show()    \n",
    " \n",
    "print(classification_report(y_test,y2_pred))\n",
    "print (\"Avg accuracy for RF \", np.array(accuracy_model_2).mean())\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test,y2_pred)\n",
    "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "print(\"roc_auc\",roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a613d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################# KNN model #################################################################\n",
    "\n",
    "from sklearn.model_selection import KFold \n",
    "kf = RepeatedKFold(n_splits=10, n_repeats=5, random_state=1)\n",
    "accuracy_model_3=[]\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "   # print(\"Train:\", train_index, \"Validation:\",test_index)\n",
    "    X_train, X_test = X[train_index], X[test_index] \n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    \n",
    "    model_3 = KNeighborsClassifier(n_neighbors=91)\n",
    "    model_3.fit(X_train, y_train)\n",
    "    y3_pred = model_3.predict(X_test)\n",
    "    accuracy_model_3.append(accuracy_score(y_test, y3_pred))\n",
    "print(accuracy_model_3) \n",
    "print (\"Avg accuracy for KNN \", np.array(accuracy_model_3).mean())\n",
    "cm = confusion_matrix(y_test, y3_pred)\n",
    "sns.heatmap(cm, annot = True, fmt = 'g')\n",
    "plt.show()\n",
    "print(classification_report(y_test,y3_pred))\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test,y3_pred)\n",
    "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "print(\"roc_auc\",roc_auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8fb490a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import xgboost as xgb\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "from sklearn.model_selection import KFold \n",
    "kf = RepeatedKFold(n_splits=10, n_repeats=5, random_state=1)\n",
    "accuracy_model_4=[]\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "   # print(\"Train:\", train_index, \"Validation:\",test_index)\n",
    "    X_train, X_test = X[train_index], X[test_index] \n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    \n",
    "    model_4 = AdaBoostClassifier(random_state=42)\n",
    "    model_4.fit(X_train, y_train)\n",
    "    y4_pred = model_4.predict(X_test)\n",
    "    accuracy_model_4.append(accuracy_score(y_test, y4_pred))\n",
    "print(accuracy_model_4) \n",
    "\n",
    "print(classification_report(y_test,y4_pred))\n",
    "print (\"Avg accuracy for AdaBoost \", np.array(accuracy_model_4).mean())\n",
    "cm = confusion_matrix(y_test, y4_pred)\n",
    "sns.heatmap(cm, annot = True, fmt = 'g')\n",
    "\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test,y4_pred)\n",
    "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "#print(\"roc_auc\",roc_auc)\n",
    "print(\"roc_auc\",roc_auc)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a13efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold \n",
    "kf = RepeatedKFold(n_splits=10, n_repeats=5, random_state=1)\n",
    "accuracy_model_5=[]\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "   # print(\"Train:\", train_index, \"Validation:\",test_index)\n",
    "    X_train, X_test = X[train_index], X[test_index] \n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    \n",
    "    model_5 = xgb.XGBClassifier(use_label_encoder =False, eval_metric='mlogloss')\n",
    "    model_5.fit(X_train, y_train)\n",
    "    y5_pred = model_5.predict(X_test)\n",
    "    accuracy_model_5.append(accuracy_score(y_test, y5_pred))\n",
    "print(accuracy_model_5) \n",
    "\n",
    "print(classification_report(y_test,y5_pred))\n",
    "print (\"Avg accuracy for XGBoost \", np.array(accuracy_model_5).mean())\n",
    "cm = confusion_matrix(y_test, y5_pred)\n",
    "sns.heatmap(cm, annot = True, fmt = 'g')\n",
    "\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test,y5_pred)\n",
    "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "#print(\"roc_auc\",roc_auc)\n",
    "print(\"roc_auc\",roc_auc)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094d00f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold \n",
    "kf = RepeatedKFold(n_splits=10, n_repeats=5, random_state=1)\n",
    "accuracy_model_5=[]\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "   # print(\"Train:\", train_index, \"Validation:\",test_index)\n",
    "    X_train, X_test = X[train_index], X[test_index] \n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    \n",
    "    model_5 = DecisionTreeClassifier( random_state = 42)\n",
    "    model_5.fit(X_train, y_train)\n",
    "    y5_pred = model_5.predict(X_test)\n",
    "    accuracy_model_5.append(accuracy_score(y_test, y5_pred))\n",
    "print(accuracy_model_5) \n",
    "\n",
    "print(classification_report(y_test,y5_pred))\n",
    "print (\"Avg accuracy for Decision tree \", np.array(accuracy_model_5).mean())\n",
    "cm = confusion_matrix(y_test, y5_pred)\n",
    "sns.heatmap(cm, annot = True, fmt = 'g')\n",
    "\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test,y5_pred)\n",
    "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "#print(\"roc_auc\",roc_auc)\n",
    "print(\"roc_auc\",roc_auc)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd07354b",
   "metadata": {},
   "source": [
    "## Approach with same models and Roc plots for 5 fold and 5 repeats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6474d726",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patches as patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98b94bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "from sklearn.model_selection import KFold \n",
    "kf = RepeatedKFold(n_splits=5, n_repeats=5, random_state=1)\n",
    "\n",
    "accuracy_model_d = []\n",
    "model_d = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# plot arrows\n",
    "fig1 = plt.figure(figsize=[12,12])\n",
    "ax1 = fig1.add_subplot(111,aspect = 'equal')\n",
    "ax1.add_patch(\n",
    "    patches.Arrow(0.45,0.5,-0.25,0.25,width=0.3,color='green',alpha = 0.5)\n",
    "    )\n",
    "ax1.add_patch(\n",
    "    patches.Arrow(0.5,0.45,0.25,-0.25,width=0.3,color='red',alpha = 0.5)\n",
    "    )\n",
    "\n",
    "tprs = []\n",
    "aucs = []\n",
    "mean_fpr = np.linspace(0,1,100)\n",
    "i = 1\n",
    "for train_index,test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index] \n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    prediction = model_d.fit(X_train,y_train).predict_proba(X_test)\n",
    "    fpr, tpr, t = roc_curve(y_test, prediction[:, 1])\n",
    "    tprs.append(interp(mean_fpr, fpr, tpr))\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    aucs.append(roc_auc)\n",
    "    ye_pred = model_d.predict(X_test)\n",
    "    accuracy_model_d.append(accuracy_score(y_test, ye_pred))\n",
    "    plt.plot(fpr, tpr, lw=2, alpha=0.3, label='ROC fold %d (AUC = %0.2f)' % (i, roc_auc))\n",
    "    i= i+1\n",
    "plt.plot([0,1],[0,1],linestyle = '--',lw = 2,color = 'black')\n",
    "mean_tpr = np.mean(tprs, axis=0)\n",
    "mean_auc = auc(mean_fpr, mean_tpr)\n",
    "plt.plot(mean_fpr, mean_tpr, color='blue',\n",
    "         label=r'Mean ROC (AUC = %0.2f )' % (mean_auc),lw=2, alpha=1)\n",
    "\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.text(0.32,0.7,'More accurate area',fontsize = 12)\n",
    "plt.text(0.63,0.4,'Less accurate area',fontsize = 12)\n",
    "plt.show()\n",
    "\n",
    "print(accuracy_model_d)\n",
    "\n",
    "print (\"Avg accuracy for Decision Tree :  \", np.array(accuracy_model_d).mean())\n",
    "cm = confusion_matrix(y_test, ye_pred)\n",
    "sns.heatmap(cm, annot = True, fmt = 'g')\n",
    "plt.show()\n",
    "\n",
    "print(classification_report(y_test,ye_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91dec3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold \n",
    "kf = RepeatedKFold(n_splits=5, n_repeats=5, random_state=1)\n",
    "\n",
    "accuracy_model_r = []\n",
    "model_r = RandomForestClassifier(max_depth=200,random_state=42)\n",
    "\n",
    "# plot arrows\n",
    "fig1 = plt.figure(figsize=[12,12])\n",
    "ax1 = fig1.add_subplot(111,aspect = 'equal')\n",
    "ax1.add_patch(\n",
    "    patches.Arrow(0.45,0.5,-0.25,0.25,width=0.3,color='green',alpha = 0.5)\n",
    "    )\n",
    "ax1.add_patch(\n",
    "    patches.Arrow(0.5,0.45,0.25,-0.25,width=0.3,color='red',alpha = 0.5)\n",
    "    )\n",
    "\n",
    "tprs = []\n",
    "aucs = []\n",
    "mean_fpr = np.linspace(0,1,100)\n",
    "i = 1\n",
    "for train_index,test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index] \n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    prediction = model_r.fit(X_train,y_train).predict_proba(X_test)\n",
    "    fpr, tpr, t = roc_curve(y_test, prediction[:, 1])\n",
    "    tprs.append(interp(mean_fpr, fpr, tpr))\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    aucs.append(roc_auc)\n",
    "    ye_pred = model_r.predict(X_test)\n",
    "    accuracy_model_r.append(accuracy_score(y_test, ye_pred))\n",
    "    plt.plot(fpr, tpr, lw=2, alpha=0.3, label='ROC fold %d (AUC = %0.2f)' % (i, roc_auc))\n",
    "    i= i+1\n",
    "plt.plot([0,1],[0,1],linestyle = '--',lw = 2,color = 'black')\n",
    "mean_tpr = np.mean(tprs, axis=0)\n",
    "mean_auc = auc(mean_fpr, mean_tpr)\n",
    "plt.plot(mean_fpr, mean_tpr, color='blue',\n",
    "         label=r'Mean ROC (AUC = %0.2f )' % (mean_auc),lw=2, alpha=1)\n",
    "\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.text(0.32,0.7,'More accurate area',fontsize = 12)\n",
    "plt.text(0.63,0.4,'Less accurate area',fontsize = 12)\n",
    "plt.show()\n",
    "\n",
    "print(accuracy_model_r)\n",
    "\n",
    "print (\"Avg accuracy for Random Forest 200:  \", np.array(accuracy_model_r).mean())\n",
    "cm = confusion_matrix(y_test, ye_pred)\n",
    "sns.heatmap(cm, annot = True, fmt = 'g')\n",
    "plt.show()\n",
    "\n",
    "print(classification_report(y_test,ye_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3e0286",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = model_r.estimators_[5]\n",
    "\n",
    "from sklearn.tree import export_graphviz\n",
    "# Export as dot file\n",
    "export_graphviz(estimator, out_file='tree.dot', \n",
    "                feature_names = iris.feature_names,\n",
    "                class_names = iris.target_names,\n",
    "                rounded = True, proportion = False, \n",
    "                precision = 2, filled = True)\n",
    "\n",
    "# Convert to png\n",
    "from subprocess import call\n",
    "call(['dot', '-Tpng', 'tree.dot', '-o', 'tree.png', '-Gdpi=600'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7196480",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.plot_tree(ye_pred);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d557922d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold \n",
    "kf = RepeatedKFold(n_splits=5, n_repeats=5, random_state=1)\n",
    "\n",
    "accuracy_model_e = []\n",
    "model_e = xgb.XGBClassifier(n_estimators = 200, eval_metric='error', use_label_encoder=False)\n",
    "\n",
    "# plot arrows\n",
    "fig1 = plt.figure(figsize=[12,12])\n",
    "ax1 = fig1.add_subplot(111,aspect = 'equal')\n",
    "ax1.add_patch(\n",
    "    patches.Arrow(0.45,0.5,-0.25,0.25,width=0.3,color='green',alpha = 0.5)\n",
    "    )\n",
    "ax1.add_patch(\n",
    "    patches.Arrow(0.5,0.45,0.25,-0.25,width=0.3,color='red',alpha = 0.5)\n",
    "    )\n",
    "\n",
    "tprs = []\n",
    "aucs = []\n",
    "mean_fpr = np.linspace(0,1,100)\n",
    "i = 1\n",
    "for train_index,test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index] \n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    prediction = model_e.fit(X_train,y_train).predict_proba(X_test)\n",
    "    fpr, tpr, t = roc_curve(y_test, prediction[:, 1])\n",
    "    tprs.append(interp(mean_fpr, fpr, tpr))\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    aucs.append(roc_auc)\n",
    "    ye_pred = model_e.predict(X_test)\n",
    "    accuracy_model_e.append(accuracy_score(y_test, ye_pred))\n",
    "    plt.plot(fpr, tpr, lw=2, alpha=0.3, label='ROC fold %d (AUC = %0.2f)' % (i, roc_auc))\n",
    "    i= i+1\n",
    "plt.plot([0,1],[0,1],linestyle = '--',lw = 2,color = 'black')\n",
    "mean_tpr = np.mean(tprs, axis=0)\n",
    "mean_auc = auc(mean_fpr, mean_tpr)\n",
    "plt.plot(mean_fpr, mean_tpr, color='blue',\n",
    "         label=r'Mean ROC (AUC = %0.2f )' % (mean_auc),lw=2, alpha=1)\n",
    "\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.text(0.32,0.7,'More accurate area',fontsize = 12)\n",
    "plt.text(0.63,0.4,'Less accurate area',fontsize = 12)\n",
    "plt.show()\n",
    "\n",
    "print(accuracy_model_e)\n",
    "\n",
    "print (\"Avg accuracy for XGBoost :  \", np.array(accuracy_model_e).mean())\n",
    "cm = confusion_matrix(y_test, ye_pred)\n",
    "sns.heatmap(cm, annot = True, fmt = 'g')\n",
    "plt.show()\n",
    "\n",
    "print(classification_report(y_test,ye_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f43ced9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import xgboost as xgb\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import KFold \n",
    "kf = RepeatedKFold(n_splits=5, n_repeats=5, random_state=1)\n",
    "\n",
    "accuracy_model_d = []\n",
    "model_d = AdaBoostClassifier(random_state=42)\n",
    "\n",
    "# plot arrows\n",
    "fig1 = plt.figure(figsize=[12,12])\n",
    "ax1 = fig1.add_subplot(111,aspect = 'equal')\n",
    "ax1.add_patch(\n",
    "    patches.Arrow(0.45,0.5,-0.25,0.25,width=0.3,color='green',alpha = 0.5)\n",
    "    )\n",
    "ax1.add_patch(\n",
    "    patches.Arrow(0.5,0.45,0.25,-0.25,width=0.3,color='red',alpha = 0.5)\n",
    "    )\n",
    "\n",
    "tprs = []\n",
    "aucs = []\n",
    "mean_fpr = np.linspace(0,1,100)\n",
    "i = 1\n",
    "for train_index,test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index] \n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    prediction = model_d.fit(X_train,y_train).predict_proba(X_test)\n",
    "    fpr, tpr, t = roc_curve(y_test, prediction[:, 1])\n",
    "    tprs.append(interp(mean_fpr, fpr, tpr))\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    aucs.append(roc_auc)\n",
    "    yd_pred = model_d.predict(X_test)\n",
    "    accuracy_model_d.append(accuracy_score(y_test, yd_pred))\n",
    "    plt.plot(fpr, tpr, lw=2, alpha=0.3, label='ROC fold %d (AUC = %0.2f)' % (i, roc_auc))\n",
    "    i= i+1\n",
    "plt.plot([0,1],[0,1],linestyle = '--',lw = 2,color = 'black')\n",
    "mean_tpr = np.mean(tprs, axis=0)\n",
    "mean_auc = auc(mean_fpr, mean_tpr)\n",
    "plt.plot(mean_fpr, mean_tpr, color='blue',\n",
    "         label=r'Mean ROC (AUC = %0.2f )' % (mean_auc),lw=2, alpha=1)\n",
    "\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.text(0.32,0.7,'More accurate area',fontsize = 12)\n",
    "plt.text(0.63,0.4,'Less accurate area',fontsize = 12)\n",
    "plt.show()\n",
    "\n",
    "print(accuracy_model_d)\n",
    "\n",
    "print (\"Avg accuracy for Adaboost \", np.array(accuracy_model_d).mean())\n",
    "cm = confusion_matrix(y_test, yd_pred)\n",
    "sns.heatmap(cm, annot = True, fmt = 'g')\n",
    "plt.show()\n",
    "\n",
    "print(classification_report(y_test,yd_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1aeb10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################ KNN model ##########################################\n",
    "\n",
    "from sklearn.model_selection import KFold \n",
    "kf = RepeatedKFold(n_splits=5, n_repeats=5, random_state=1)\n",
    "\n",
    "accuracy_model_c = []\n",
    "model_c = KNeighborsClassifier(n_neighbors=91)\n",
    "\n",
    "# plot arrows\n",
    "fig1 = plt.figure(figsize=[12,12])\n",
    "ax1 = fig1.add_subplot(111,aspect = 'equal')\n",
    "ax1.add_patch(\n",
    "    patches.Arrow(0.45,0.5,-0.25,0.25,width=0.3,color='green',alpha = 0.5)\n",
    "    )\n",
    "ax1.add_patch(\n",
    "    patches.Arrow(0.5,0.45,0.25,-0.25,width=0.3,color='red',alpha = 0.5)\n",
    "    )\n",
    "\n",
    "tprs = []\n",
    "aucs = []\n",
    "mean_fpr = np.linspace(0,1,100)\n",
    "i = 1\n",
    "for train_index,test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index] \n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    prediction = model_c.fit(X_train,y_train).predict_proba(X_test)\n",
    "    fpr, tpr, t = roc_curve(y_test, prediction[:, 1])\n",
    "    tprs.append(interp(mean_fpr, fpr, tpr))\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    aucs.append(roc_auc)\n",
    "    yc_pred = model_c.predict(X_test)\n",
    "    accuracy_model_c.append(accuracy_score(y_test, yc_pred))\n",
    "    plt.plot(fpr, tpr, lw=2, alpha=0.3, label='ROC fold %d (AUC = %0.2f)' % (i, roc_auc))\n",
    "    i= i+1\n",
    "plt.plot([0,1],[0,1],linestyle = '--',lw = 2,color = 'black')\n",
    "mean_tpr = np.mean(tprs, axis=0)\n",
    "mean_auc = auc(mean_fpr, mean_tpr)\n",
    "plt.plot(mean_fpr, mean_tpr, color='blue',\n",
    "         label=r'Mean ROC (AUC = %0.2f )' % (mean_auc),lw=2, alpha=1)\n",
    "\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.text(0.32,0.7,'More accurate area',fontsize = 12)\n",
    "plt.text(0.63,0.4,'Less accurate area',fontsize = 12)\n",
    "plt.show()\n",
    "\n",
    "print(accuracy_model_c)\n",
    "\n",
    "print (\"Avg accuracy for KNN : \", np.array(accuracy_model_c).mean())\n",
    "cm = confusion_matrix(y_test, yc_pred)\n",
    "sns.heatmap(cm, annot = True, fmt = 'g')\n",
    "plt.show()\n",
    "\n",
    "print(classification_report(y_test,yc_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd925b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################LR model ##########################################\n",
    "\n",
    "import matplotlib.patches as patches\n",
    "from sklearn.model_selection import KFold \n",
    "kf = RepeatedKFold(n_splits=5, n_repeats=5, random_state=1)\n",
    "accuracy_model_a = []\n",
    "model_a = LogisticRegression(random_state=42, max_iter= 10**4)\n",
    "\n",
    "# plot arrows\n",
    "fig1 = plt.figure(figsize=[12,12])\n",
    "ax1 = fig1.add_subplot(111,aspect = 'equal')\n",
    "ax1.add_patch(\n",
    "    patches.Arrow(0.45,0.5,-0.25,0.25,width=0.3,color='green',alpha = 0.5)\n",
    "    )\n",
    "ax1.add_patch(\n",
    "    patches.Arrow(0.5,0.45,0.25,-0.25,width=0.3,color='red',alpha = 0.5)\n",
    "    )\n",
    "\n",
    "tprs = []\n",
    "aucs = []\n",
    "mean_fpr = np.linspace(0,1,100)\n",
    "i = 1\n",
    "for train_index,test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index] \n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    prediction = model_a.fit(X_train,y_train).predict_proba(X_test)\n",
    "    fpr, tpr, t = roc_curve(y_test, prediction[:, 1])\n",
    "    tprs.append(interp(mean_fpr, fpr, tpr))\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    aucs.append(roc_auc)\n",
    "    ya_pred = model_a.predict(X_test)\n",
    "    accuracy_model_a.append(accuracy_score(y_test, ya_pred))\n",
    "    plt.plot(fpr, tpr, lw=2, alpha=0.3, label='ROC fold %d (AUC = %0.2f)' % (i, roc_auc))\n",
    "    i= i+1\n",
    "plt.plot([0,1],[0,1],linestyle = '--',lw = 2,color = 'black')\n",
    "mean_tpr = np.mean(tprs, axis=0)\n",
    "mean_auc = auc(mean_fpr, mean_tpr)\n",
    "plt.plot(mean_fpr, mean_tpr, color='blue',\n",
    "         label=r'Mean ROC (AUC = %0.2f )' % (mean_auc),lw=2, alpha=1)\n",
    "\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.text(0.32,0.7,'More accurate area',fontsize = 12)\n",
    "plt.text(0.63,0.4,'Less accurate area',fontsize = 12)\n",
    "plt.show()\n",
    "\n",
    "print(accuracy_model_a)\n",
    "\n",
    "print (\"Avg accuracy for LR:  \", np.array(accuracy_model_a).mean())\n",
    "cm = confusion_matrix(y_test, ya_pred)\n",
    "sns.heatmap(cm, annot = True, fmt = 'g')\n",
    "plt.show()\n",
    "\n",
    "print(classification_report(y_test,ya_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83cc26d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RepeatedKFold \n",
    "import xgboost as xgb\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "kf = RepeatedKFold(n_splits=5, n_repeats=5, random_state=1)\n",
    "\n",
    "accuracy_model_e = []\n",
    "model_e = xgb.XGBClassifier(use_label_encoder =False, eval_metric='mlogloss', )\n",
    "accuracy_model_d = []\n",
    "model_d = AdaBoostClassifier(random_state=42)\n",
    "accuracy_model_c = []\n",
    "model_c = KNeighborsClassifier(n_neighbors=91)\n",
    "accuracy_model_b = []\n",
    "model_b = RandomForestClassifier(n_estimators=100, random_state=521)\n",
    "accuracy_model_b1 = []\n",
    "model_b1 = RandomForestClassifier(n_estimators=200, random_state=521)\n",
    "accuracy_model_a = []\n",
    "model_a = LogisticRegression(random_state=42, max_iter= 10**6)\n",
    "accuracy_model_f = []\n",
    "model_f = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "fig1 = plt.figure(figsize=[8,6])\n",
    "\n",
    "tprs = []\n",
    "aucs = []\n",
    "mean_fpr = np.linspace(0,1,100)\n",
    "i = 1\n",
    "for train_index,test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index] \n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    prediction = model_d.fit(X_train,y_train).predict_proba(X_test)\n",
    "    fpr, tpr, t = roc_curve(y_test, prediction[:, 1])\n",
    "    tprs.append(np.interp(mean_fpr, fpr, tpr))\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    aucs.append(roc_auc)\n",
    "    yd_pred = model_d.predict(X_test)\n",
    "    accuracy_model_d.append(accuracy_score(y_test, yd_pred))\n",
    "    #plt.plot(fpr, tpr, lw=2, alpha=0.3, label='ROC fold %d (AUC = %0.2f)' % (i, roc_auc))\n",
    "    i= i+1\n",
    "plt.plot([0,1],[0,1],linestyle = '--',lw = 2,color = 'black')\n",
    "mean_tpr = np.mean(tprs, axis=0)\n",
    "mean_auc = auc(mean_fpr, mean_tpr)\n",
    "plt.plot(mean_fpr, mean_tpr, color='blue',\n",
    "         label=r'Mean ROC AdaBoost(AUC = %0.2f )' % (mean_auc),lw=2, alpha=1)\n",
    "\n",
    "\n",
    "\n",
    "tprs = []\n",
    "aucs = []\n",
    "mean_fpr = np.linspace(0,1,100)\n",
    "i = 1\n",
    "for train_index,test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index] \n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    prediction = model_e.fit(X_train,y_train).predict_proba(X_test)\n",
    "    fpr, tpr, t = roc_curve(y_test, prediction[:, 1])\n",
    "    tprs.append(np.interp(mean_fpr, fpr, tpr))\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    aucs.append(roc_auc)\n",
    "    ye_pred = model_e.predict(X_test)\n",
    "    accuracy_model_e.append(accuracy_score(y_test, ye_pred))\n",
    "    #plt.plot(fpr, tpr, lw=2, alpha=0.3, label='ROC fold %d (AUC = %0.2f)' % (i, roc_auc))\n",
    "    i= i+1\n",
    "plt.plot([0,1],[0,1],linestyle = '--',lw = 2,color = 'black')\n",
    "mean_tpr = np.mean(tprs, axis=0)\n",
    "mean_auc = auc(mean_fpr, mean_tpr)\n",
    "plt.plot(mean_fpr, mean_tpr, color='black',\n",
    "         label=r'Mean ROC XGBoost (AUC = %0.2f )' % (mean_auc),lw=2, alpha=1)\n",
    "\n",
    "\n",
    "tprs = []\n",
    "aucs = []\n",
    "mean_fpr = np.linspace(0,1,100)\n",
    "i = 1\n",
    "for train_index,test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index] \n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    prediction = model_a.fit(X_train,y_train).predict_proba(X_test)\n",
    "    fpr, tpr, t = roc_curve(y_test, prediction[:, 1])\n",
    "    tprs.append(np.interp(mean_fpr, fpr, tpr))\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    aucs.append(roc_auc)\n",
    "    ya_pred = model_e.predict(X_test)\n",
    "    accuracy_model_a.append(accuracy_score(y_test, ya_pred))\n",
    "    #plt.plot(fpr, tpr, lw=2, alpha=0.3, label='ROC fold %d (AUC = %0.2f)' % (i, roc_auc))\n",
    "    i= i+1\n",
    "plt.plot([0,1],[0,1],linestyle = '--',lw = 2,color = 'black')\n",
    "mean_tpr = np.mean(tprs, axis=0)\n",
    "mean_auc = auc(mean_fpr, mean_tpr)\n",
    "plt.plot(mean_fpr, mean_tpr, color='green',\n",
    "         label=r'Mean ROC LR, (AUC = %0.2f )' % (mean_auc),lw=2, alpha=1)\n",
    "\n",
    "\n",
    "tprs = []\n",
    "aucs = []\n",
    "mean_fpr = np.linspace(0,1,100)\n",
    "i = 1\n",
    "for train_index,test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index] \n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    prediction = model_b.fit(X_train,y_train).predict_proba(X_test)\n",
    "    fpr, tpr, t = roc_curve(y_test, prediction[:, 1])\n",
    "    tprs.append(np.interp(mean_fpr, fpr, tpr))\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    aucs.append(roc_auc)\n",
    "    yb_pred = model_b.predict(X_test)\n",
    "    accuracy_model_b.append(accuracy_score(y_test, yb_pred))\n",
    "    #plt.plot(fpr, tpr, lw=2, alpha=0.3, label='ROC fold %d (AUC = %0.2f)' % (i, roc_auc))\n",
    "    i= i+1\n",
    "plt.plot([0,1],[0,1],linestyle = '--',lw = 2,color = 'black')\n",
    "mean_tpr = np.mean(tprs, axis=0)\n",
    "mean_auc = auc(mean_fpr, mean_tpr)\n",
    "plt.plot(mean_fpr, mean_tpr, color='yellow',\n",
    "         label=r'Mean ROC RF 100, (AUC = %0.2f )' % (mean_auc),lw=2, alpha=1)\n",
    "\n",
    "tprs = []\n",
    "aucs = []\n",
    "mean_fpr = np.linspace(0,1,100)\n",
    "i = 1\n",
    "for train_index,test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index] \n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    prediction = model_b1.fit(X_train,y_train).predict_proba(X_test)\n",
    "    fpr, tpr, t = roc_curve(y_test, prediction[:, 1])\n",
    "    tprs.append(np.interp(mean_fpr, fpr, tpr))\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    aucs.append(roc_auc)\n",
    "    yb1_pred = model_b1.predict(X_test)\n",
    "    accuracy_model_b1.append(accuracy_score(y_test, yb1_pred))\n",
    "    #plt.plot(fpr, tpr, lw=2, alpha=0.3, label='ROC fold %d (AUC = %0.2f)' % (i, roc_auc))\n",
    "    i= i+1\n",
    "plt.plot([0,1],[0,1],linestyle = '--',lw = 2,color = 'black')\n",
    "mean_tpr = np.mean(tprs, axis=0)\n",
    "mean_auc = auc(mean_fpr, mean_tpr)\n",
    "plt.plot(mean_fpr, mean_tpr, color='purple',\n",
    "         label=r'Mean ROC RF 200, (AUC = %0.2f )' % (mean_auc),lw=2, alpha=1)\n",
    "\n",
    "tprs = []\n",
    "aucs = []\n",
    "mean_fpr = np.linspace(0,1,100)\n",
    "i = 1\n",
    "for train_index,test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index] \n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    prediction = model_c.fit(X_train,y_train).predict_proba(X_test)\n",
    "    fpr, tpr, t = roc_curve(y_test, prediction[:, 1])\n",
    "    tprs.append(np.interp(mean_fpr, fpr, tpr))\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    aucs.append(roc_auc)\n",
    "    yc_pred = model_c.predict(X_test)\n",
    "    accuracy_model_c.append(accuracy_score(y_test, yc_pred))\n",
    "    #plt.plot(fpr, tpr, lw=2, alpha=0.3, label='ROC fold %d (AUC = %0.2f)' % (i, roc_auc))\n",
    "    i= i+1\n",
    "plt.plot([0,1],[0,1],linestyle = '--',lw = 2,color = 'black')\n",
    "mean_tpr = np.mean(tprs, axis=0)\n",
    "mean_auc = auc(mean_fpr, mean_tpr)\n",
    "plt.plot(mean_fpr, mean_tpr, color='orange',\n",
    "         label=r'Mean ROC KNN, (AUC = %0.2f )' % (mean_auc),lw=2, alpha=1)\n",
    "\n",
    "\n",
    "tprs = []\n",
    "aucs = []\n",
    "mean_fpr = np.linspace(0,1,100)\n",
    "i = 1\n",
    "for train_index,test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index] \n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    prediction = model_f.fit(X_train,y_train).predict_proba(X_test)\n",
    "    fpr, tpr, t = roc_curve(y_test, prediction[:, 1])\n",
    "    tprs.append(np.interp(mean_fpr, fpr, tpr))\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    aucs.append(roc_auc)\n",
    "    yf_pred = model_f.predict(X_test)\n",
    "    accuracy_model_f.append(accuracy_score(y_test, yf_pred))\n",
    "    #plt.plot(fpr, tpr, lw=2, alpha=0.3, label='ROC fold %d (AUC = %0.2f)' % (i, roc_auc))\n",
    "    i= i+1\n",
    "plt.plot([0,1],[0,1],linestyle = '--',lw = 2,color = 'black')\n",
    "mean_tpr = np.mean(tprs, axis=0)\n",
    "mean_auc = auc(mean_fpr, mean_tpr)\n",
    "plt.plot(mean_fpr, mean_tpr, color='magenta',\n",
    "         label=r'Mean ROC DT, (AUC = %0.2f )' % (mean_auc),lw=2, alpha=1)\n",
    "\n",
    "\n",
    "\n",
    "plt.xticks(np.arange(0.0, 1.1, step=0.1))\n",
    "plt.xlabel(\"False Positive Rate\", fontsize=14)\n",
    "plt.yticks(np.arange(0.0, 1.1, step=0.1))\n",
    "plt.ylabel('True Positive Rate', fontsize=14)\n",
    "plt.title('ROC')\n",
    "plt.legend(loc=\"lower right\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b3a0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig('multiple_roc_curve_comparison.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
